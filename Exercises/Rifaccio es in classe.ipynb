{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "cd168fe6",
      "metadata": {
        "id": "cd168fe6"
      },
      "source": [
        "# Classification task using a perceptron\n",
        "\n",
        "Create a dataset with three classes, each class has N objects, represented by two variables X1 and X2 according to the following requirements:\n",
        "\n",
        "+ N is equal to 100\n",
        "+ X1 is distributed:\n",
        "    1. for class 1, a normal distribution with mean -1 and standard deviation 0.5\n",
        "    2. for class 2, a normal distribution with mean 2.5 and standard deviation 1\n",
        "    3. for class 3, a normal distribution with mean 4 and standard deviation 1\n",
        "+ X2 is distributed:\n",
        "    1. for class 1, an exponential distribution with scale parameter 3\n",
        "    2. for class 2, a lognormal distribution with mean 0.5 and standard deviation 0.5\n",
        "    3. for class 3, a Poisson distribution with lambda 2.0 plus a constant equal to 5\n",
        "\n",
        "Each object has a label y attached (1, 2, or 3)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "30602c9d",
      "metadata": {
        "id": "30602c9d"
      },
      "source": [
        "## Plot the points"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b51a614b",
      "metadata": {
        "id": "b51a614b"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "N = 100\n",
        "np.random.seed(123)\n",
        "\n",
        "X1_1 = np.random.normal(loc=-1, scale=0.5, size=N)\n",
        "X1_2 = np.random.normal(loc= 2.5 , scale= 1 , size=N) \n",
        "X1_3 = np.random.normal(loc=4, scale=1, size=N)\n",
        "\n",
        "X2_1 = np.random.exponential(scale=3, size=N)\n",
        "X2_2 = np.random.lognormal(mean=0.5,sigma=0.5 ,size= N)\n",
        "X2_3 = np.random.poisson(lam= 2,size=N) + 5\n",
        "\n",
        "\n",
        "#creo i vettori label\n",
        "y1=np.ones(N)\n",
        "y2=np.ones(N)*2\n",
        "y3=np.ones(N)*3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "193dbef0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "193dbef0",
        "outputId": "cb7a364d-e1f4-4e4a-e13d-30569f4f7aaa"
      },
      "outputs": [],
      "source": [
        "#faccio i plot delle varie distrubuzioni\n",
        "\n",
        "plt.scatter(X1_1,X2_1)\n",
        "plt.scatter(X1_2,X2_2)\n",
        "plt.scatter(X1_3,X2_3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "91709f4a",
      "metadata": {
        "id": "91709f4a"
      },
      "source": [
        "## Create data matrix\n",
        "\n",
        "Create a matrix of points X (each row is an object) and a vector y of labels. Remember that we need the coordinate X0 for the bias term (all ones)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e68c370e",
      "metadata": {
        "id": "e68c370e"
      },
      "outputs": [],
      "source": [
        "#bias term vector \n",
        "X0= np.ones(N*3)\n",
        "\n",
        "X = np.stack((X0,\n",
        "    np.concatenate((X1_1,X1_2,X1_3)),\n",
        "    np.concatenate((X2_1,X2_2,X2_3))),\n",
        "    axis=1) \n",
        "\n",
        "y=np.concatenate((y1,y2,y3))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c820f645",
      "metadata": {
        "id": "c820f645"
      },
      "source": [
        "## Choose category \n",
        "\n",
        "We want to train a binary classifier for class 3. To this purpose, create a vector of labels y_class that contains 1 for each object belonging to the class under study (positive class) and -1 to all the other objects.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1c16b138",
      "metadata": {
        "id": "1c16b138"
      },
      "outputs": [],
      "source": [
        "positive_class=3\n",
        "\n",
        "y_class = -np.ones(N*3)\n",
        "y_class[y==positive_class]=1"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "62eb526c",
      "metadata": {
        "id": "62eb526c"
      },
      "source": [
        "### Plot this binary problem"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "03e4e3b0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "03e4e3b0",
        "outputId": "67603bf5-46da-4429-c6df-617f9b0bb4dc"
      },
      "outputs": [],
      "source": [
        "plt.scatter(X[:,1], X[:,2], c=y_class) "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f36eeb13",
      "metadata": {
        "id": "f36eeb13"
      },
      "source": [
        "## Define the Sum of squares error function\n",
        "\n",
        "Write the function sse(X, y, w) that takes the data matrix X, the labels y, and the vector of paraterers w and computes the error in terms of sum of squares."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d58b3acf",
      "metadata": {
        "id": "d58b3acf"
      },
      "outputs": [],
      "source": [
        "def sse(X, y, w):\n",
        "    error = np.sum(np.square(y-np.dot(X,w)))/2#sum of squares error \n",
        "    return error"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b18c0253",
      "metadata": {
        "id": "b18c0253"
      },
      "source": [
        "## Train the perceptron with a mini-batch stochastic gradient descent\n",
        "\n",
        "Set the values of the vector of parameters w with values drawn from a uniform distribution within the range \\[-1. 1\\].\n",
        "Use a learning parameter eta equal to 1e-5 and a batch size of 10 objects. Set the maximum number of epochs to 100.\n",
        "Save in the vector sse_epoch, the values of the sum of squares error for each epoch. Save in the vector errors_epoch, the number of objects misclassified at each epoch.\n",
        "Remember to shuffle the dataset at each epoch."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "28f8ec5b",
      "metadata": {
        "id": "28f8ec5b"
      },
      "outputs": [],
      "source": [
        "w= np.random.uniform(low=-1,high=1 , size =3)\n",
        "\n",
        "mini_batch_size= 10 \n",
        "max_epoch = 100\n",
        "epoch= 0 \n",
        "\n",
        "eta = 1e-5\n",
        "\n",
        "#mi creo i vettori per salvare gli errori\n",
        "sse_epoch = np.zeros(max_epoch+1)\n",
        "\n",
        "#set checkpoint \n",
        "errors_epoch = np.zeros(max_epoch+1)\n",
        "\n",
        "for epoch in range(max_epoch) :\n",
        "    sse_epoch[epoch] = sse(X, y_class, w)\n",
        "    errors_epoch[epoch] = sum((y_class * np.sign(np.dot(X, w))) <0) #ho errore solo quando i segni sono discordi \n",
        "\n",
        "    #faccio le permutazioni di X\n",
        "    perm = np.random.permutation(range(y_class.shape[0]))\n",
        "    X=X[perm, :]\n",
        "    y_class = y_class[perm]\n",
        "\n",
        "    for j in range(0, y_class.shape[0], mini_batch_size): #parto da 0 e vado a 100 facendo passi da 10 \n",
        "       \n",
        "        #faccio un trim delle classi di analisi \n",
        "        X_batch = X[j:(j+mini_batch_size)]\n",
        "        y_batch = y_class[j:(j+mini_batch_size)]\n",
        "        errors = y_batch - np.dot(X_batch, w)\n",
        "       \n",
        "        w = w + eta + np.dot(X_batch.T,errors)\n",
        "\n",
        "#errori dell'ultima epoca\n",
        "sse_epoch[epoch+1]= sse (X, y_class, w)\n",
        "errors_epoch[epoch+1] = sum((y_class * np.sign(np.dot(X, w)))<0)\n",
        "\n",
        "print (errors_epoch)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86445ce4",
      "metadata": {
        "id": "86445ce4"
      },
      "source": [
        "## Plot number of errors per epoch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7712ecc1",
      "metadata": {
        "id": "7712ecc1"
      },
      "outputs": [],
      "source": [
        "plt.plot(errors_epoch)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d385b99b",
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "id": "a6a18977",
      "metadata": {
        "id": "a6a18977"
      },
      "source": [
        "# Polynomial regression task\n",
        "\n",
        "In this exercies, we will reuse the coordinate X1 to create a regression problem. The output Y (the \"oracle\" target function) is a cubic function aX^3 + bX^2 + cX + d with values a = -1, b = 2, c = -3, d = 4. Moreover, we sum some randome noise with a gaussian distribution (mean zero, standard deviation 2.5)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1a55d57d",
      "metadata": {
        "id": "1a55d57d"
      },
      "outputs": [],
      "source": [
        "\n",
        "a = -1\n",
        "b = 2\n",
        "c = -3\n",
        "d = 4\n",
        "\n",
        "X1 = np.concatenate((X1_1,X1_2,X1_3),  axis= 0)\n",
        "disturbo = np.random.normal(loc=0, scale=0.5, size=N*3)\n",
        "\n",
        "#creo la funzione oracolo\n",
        "y = a*pow(X1,3) + b*pow(X1,2) + c*X1+ d + disturbo\n",
        "\n",
        "#non richiesto dalla consegna\n",
        "plt.scatter(X1,y)\n",
        "#il prof usa plot con label '.'"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8adb301c",
      "metadata": {
        "id": "8adb301c"
      },
      "source": [
        "## Create data matrix\n",
        "Suppose that your hypohtesis is a quadratic function, generate the data matrix accordingly (remember the X0) and save it into the variable X_reg."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ccfff3a",
      "metadata": {
        "id": "1ccfff3a"
      },
      "outputs": [],
      "source": [
        "X0= np.one(N)\n",
        "X_reg= np.hstack([X0,X1,X1**2])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f352f40f",
      "metadata": {
        "id": "f352f40f"
      },
      "source": [
        "## Find the optimal vector of parameters\n",
        "In this case, we will try to find the optimal w using the closed form."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2deb9b9b",
      "metadata": {
        "id": "2deb9b9b"
      },
      "outputs": [],
      "source": [
        "#assegno dei valori random al vettore dei pesi \n",
        "w = np.random.uniform (low=-1, high = 1, size= 3)\n",
        "\n",
        "#parametri \n",
        "eta = 1e-5\n",
        "\n",
        "#per trovare la migliore soluzione uso lo stochastic gradient descent quindi \n",
        "#devo anche impostare il batch size\n",
        "print (mini_batch_size,'mini batch size = ') #uso quella della task precedente \n",
        "\n",
        "#per sicurezza aumento il numero di epochs\n",
        "max_epoch= 2000\n",
        "\n",
        "#imposto un vettore dove sommo gli errori in ogni epoca\n",
        "total_error= np.zeros(max.epochs+1)\n",
        "\n",
        "#definisco la funzione degli errori \n",
        "def error_w(X,y,w):\n",
        "    error= np.sum (np.square(y-np.dot(X,w))) / 2.0\n",
        "    return error \n",
        "\n",
        "#inizio il learning \n",
        "for epochs in range(max_epoch):\n",
        "    total_error[epoch]= error_w(X_reg,y,w)\n",
        "\n",
        "    #genero delle permutazioni casuali (mini batch)\n",
        "    perm = np.random.permutation(range(y.shape[0]))\n",
        "    X_reg= X_reg[perm,:]\n",
        "    y = y[perm,:]\n",
        "    # mini batch\n",
        "    for j in range(0,y.shape[0],mini_batch_size):\n",
        "        \n",
        "        X_batch = X[j:(j + mini_batch_size), :]\n",
        "        \n",
        "        y_batch = y[j:(j + mini_batch_size)]\n",
        "        \n",
        "        errors = y_batch - np.dot(X_batch, w)\n",
        "        \n",
        "        w = w + eta * np.dot(np.transpose(X_batch), errors)    \n",
        "\n",
        "#come vettore di peso corretto uso l'ultimo vettore trovato\n",
        "#volendo potrei anche usare la media calcolata ad ogni iterazione "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6062ad8f",
      "metadata": {
        "id": "6062ad8f"
      },
      "source": [
        "## Check the curvature of the solution\n",
        "\n",
        "Why does this solution look like a line? Try to plot the parabola and think about the reasons of this shape."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e09d7217",
      "metadata": {
        "id": "e09d7217"
      },
      "outputs": [],
      "source": [
        "# genero dei punti per plottare la linea\n",
        "x_grid = np.linspace(0, 5, 100) \n",
        "\n",
        "# plot line\n",
        "plt.plot(x_grid, w[0] + x_grid * w[1] + x_grid**2 * w[2])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Esercizio in classe.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
