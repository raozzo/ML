{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Fundamentals of Information Systems\n",
    "\n",
    "## Python Programming (for Data Science)\n",
    "\n",
    "### Master's Degree in Data Science\n",
    "\n",
    "#### Giorgio Maria Di Nunzio\n",
    "#### (Courtesy of Gabriele Tolomei FIS 2018-2019)\n",
    "<a href=\"mailto:giorgiomaria.dinunzio@unipd.it\">giorgiomaria.dinunzio@unipd.it</a><br/>\n",
    "University of Padua, Italy<br/>\n",
    "2021/2022<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Lecture 8: I/O with <code>pandas</code>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Overview\n",
    "\n",
    "-  Accessing data is a necessary first step for any data scientist. \n",
    "\n",
    "-  We are going to see how to perform data input/output operations using <code>**pandas**</code>.\n",
    "\n",
    "-  I/O might refer to: reading from/writing to text files (or other more efficient on-disk formats), accessing databases, interacting with network sources like web APIs, etc.\n",
    "\n",
    "-  We will be exploring each of those separately (although we will be focusing more on text files)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Loading Data into <code>DataFrame</code> Objects\n",
    "\n",
    "-  There are many functions that allow <code>**pandas**</code> to read tabular data as a <code>**DataFrame**</code> object. \n",
    "\n",
    "-  Among those, <code>**read_csv**</code> and <code>**read_table**</code> are by far the ones you'll likely use the most."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Optional Arguments to <code>read_*</code> Functions\n",
    "\n",
    "-  **Indexing:** can treat one or more columns as the returned <code>**DataFrame**</code>, and whether to get column names from the file, the user, or not at all.\n",
    "\n",
    "-  **Type inference and data conversion:** this includes the user-defined value conversions and custom list of missing value markers.\n",
    "\n",
    "-  **Datetime parsing:** includes combining date and time information spread over multiple columns into a single column in the result.\n",
    "\n",
    "-  **Iterating:** support for iterating over chunks of very large files.\n",
    "\n",
    "-  **Unclean data issues:** skipping rows or a footer, comments, or other minor things like numeric data with thousands separated by commas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Too Many Optional Arguments\n",
    "\n",
    "-  Because of how messy data in the real world can be, some of the data loading functions (especially <code>**read_csv**</code>) have grown very complex over time. \n",
    "\n",
    "-  To avoid feeling ovewhelmed by the huge number of possible options, please refer to the [online pandas documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html).\n",
    "\n",
    "-  Type inference is one of the more important features of these functions; that means you don't necessarily have to specify which columns are numeric, integer, boolean, or string."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## <code>read_csv</code>/<code>read_table</code>\n",
    "\n",
    "-  We will explore some of the most important I/O features provided by <code>**pandas**</code> using an example.\n",
    "\n",
    "-  To this end, we use a tabular data file located on a remote server.\n",
    "\n",
    "-  To check out how such a file looks like, just click [here](https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user).\n",
    "\n",
    "-  Of course, you can save this file on your machine and load it locally from there with <code>**pandas**</code>.\n",
    "\n",
    "-  By default, data is assumed to be **tab-separated** (<code>**'\\t'**</code>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's start with a real example on how to load a tabular data file using pandas.\n",
    "\"\"\"\n",
    "# Locate the dataset (in this case, we use a remote file located on an external server)\n",
    "# Alternatively, you can save this file on your machine and load it locally from there.\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/justmarkham/DAT8/master/data/u.user'\n",
    "\n",
    "# The first line of the file represents the header, and each field\n",
    "# is separated by a pipe\n",
    "\"\"\"\n",
    "We specify the url where the data is located, the character used to separate fields ('|')\n",
    "and the name of the column to use as row label (otherwise, RangeInteger will be used)\n",
    "\"\"\"\n",
    "users = pd.read_csv(url, sep = '|', index_col = 'user_id')\n",
    "print(users.tail(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we have stored the file on our local machine.\n",
    "\"\"\"\n",
    "path = './data/user_occupations.txt'\n",
    "\n",
    "# read users\n",
    "users = pd.read_csv(path, sep='|', index_col='user_id')\n",
    "print(users.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose the file does not contain any header line. We can still load the file\n",
    "telling pandas there is no header AND we can also provide pandas with a list \n",
    "of names corresponding to the header we want to use.\n",
    "\"\"\"\n",
    "# This is the path to the same file yet without the header line\n",
    "path_no_header = './data/user_occupations_no_header.txt'\n",
    "\n",
    "# If the file does not contain the header as the first line\n",
    "users = pd.read_csv(path_no_header, sep = '|')\n",
    "\n",
    "# Row and column indices fall back to the default RangeIndex (i.e., integers)\n",
    "print(users.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# If the file does not contain the header as the first line AND we want to\n",
    "# specify ourselves the names of the columns (and, possibly, the row index as well)\n",
    "users = pd.read_csv(path_no_header, \n",
    "                    sep = '|', \n",
    "                    header = None, \n",
    "                    names = ['user_id', 'age', 'gender', 'occupation', 'zip_code'],\n",
    "                    index_col = 'user_id'\n",
    "                   )\n",
    "\n",
    "print(users.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Sometimes, it may be useful to skip some records of the input file.\n",
    "# Here, we skip the first, third and fourth (actual) record.\n",
    "users_skip = pd.read_csv(path_no_header, \n",
    "                         sep = '|', \n",
    "                         header = None,\n",
    "                         names=['user_id', 'age', 'gender', 'occupation', 'zip_code'],\n",
    "                         index_col = 'user_id',\n",
    "                         skiprows = [0, 1, 5])\n",
    "\n",
    "print(users_skip.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Handling Missing Values (*NA* or *Not Available*)\n",
    "\n",
    "-  Missing data is usually either not present (i.e., empty string) or marked by some **sentinel** value. \n",
    "\n",
    "-  By default, <code>**pandas**</code> uses a set of commonly occurring sentinels, such as <code>**None**</code> and <code>**NaN**</code>.\n",
    "\n",
    "-  The <code>**na_values**</code> is used to customize sentinel values by adding to the default ones either a list or set of strings to consider missing values.\n",
    "\n",
    "-  Chech the guide about [working with missing data](https://pandas-docs.github.io/pandas-docs-travis/user_guide/missing_data.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to mark as NA any entry whose value is 'N/A'.\n",
    "\"\"\"\n",
    "# Load again the data with the option for handling missing values (na_values)\n",
    "users = pd.read_csv(path, \n",
    "                    sep='|', \n",
    "                    index_col = 'user_id', \n",
    "                    na_values = ['N/A'])\n",
    "\n",
    "# Alternatively, we can define a dictionary of sentinels, i.e., a set for each column.\n",
    "sentinels = {'age': ['inf', 'N/A'], 'zip_code': ['00000']}\n",
    "\n",
    "users = pd.read_csv(path, sep='|', index_col='user_id', na_values = sentinels)\n",
    "print(users.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reading Text Files in Pieces\n",
    "\n",
    "-  When processing very large files, you may only want to read in a small piece of a file or iterate through smaller chunks of the file.\n",
    "\n",
    "-  If we want to only read out a small number of rows (avoiding reading the entire file), specify that with <code>**nrows**</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to just read 100 records from our file.\n",
    "\"\"\"\n",
    "# Specify the number of rows to be read\n",
    "users_100 = pd.read_csv(path, sep='|', index_col='user_id', nrows = 100)\n",
    "\n",
    "\n",
    "\n",
    "# Verify that we actually read that many rows\n",
    "print(\"Number of observations (#rows) = {}\".format(users_100.shape[0]))\n",
    "users_100.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's reload the dataset from the remote file.\n",
    "\"\"\"\n",
    "users = pd.read_csv(path, sep='|', index_col='user_id')\n",
    "print(users.head())\n",
    "users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's print out some information about the data we just loaded.\n",
    "\"\"\"\n",
    "print(\"Number of observations (#rows) = {}\".format(users.shape[0]))\n",
    "\n",
    "print(\"Number of fields (#columns) = {}\".format(users.shape[1]))\n",
    "\n",
    "print(\"Column names = [{}]\".format(\", \".join([c for c in users.columns])))\n",
    "\n",
    "print(\"The index (i.e., the labels) is:\\n{}\".format(users.index))\n",
    "\n",
    "print(\"The data types of each column are:\\n{}\".format(users.dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to access a single column of the DataFrame.\n",
    "\"\"\"\n",
    "# Let's return the first 5 values of the 'occupation' column.\n",
    "print(users['occupation'][:5]) # alternatively, use users['occupation'].head()\n",
    "print()\n",
    "\n",
    "# The same can be obtained using '.' notation\n",
    "print(users.occupation[:5]) # alternatively, use users.occupation.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to access a single column of the DataFrame.\n",
    "\"\"\"\n",
    "# Let's return the first 5 values of the 'occupation' column.\n",
    "print(users.loc[:5, 'occupation'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's now create a deep copy of the loaded DataFrame 'users'.\n",
    "Remember: assigning another name to the same DataFrame is simple a view.\n",
    "For example, users_df = users makes users_df point to the same users. As such,\n",
    "any change to the content of the DataFrame while working on users_df is reflected to users.\n",
    "\"\"\"\n",
    "# Make a deep copy of users\n",
    "users_df = users.copy()\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's add an extra column to the DataFrame and populate this column\n",
    "with some values (e.g., a series)\n",
    "\"\"\"\n",
    "# Suppose we want to add an extra column 'salary', which we randomly populate\n",
    "# with values in the range [5000, 1000000]\n",
    "np.random.seed(142) # Initialize internal state of the random number generator\n",
    "\n",
    "# set base salary\n",
    "BASE_SALARY = 5000\n",
    "\n",
    "# build values\n",
    "values = pd.Series(np.random.randint(995000, size=users_df.shape[0]) + BASE_SALARY)\n",
    "print(values.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Before we actually \"join\" the Series we have just created with our users DataFrame,\n",
    "we need the index of both objects to be aligned. Otherwise, there won't be any salary\n",
    "associated with the DataFrame row index 943, as the Series index is shifted by 1 w.r.t.\n",
    "the index of our DataFrame. Let's specify the index when creating our salary values.\n",
    "\"\"\"\n",
    "np.random.seed(42) # Initialize internal state of the random number generator\n",
    "BASE_SALARY = 5000\n",
    "\n",
    "# add index\n",
    "values = pd.Series(np.random.randint(995000, size=users_df.shape[0]) + BASE_SALARY,\n",
    "                  index=users_df.index)\n",
    "print(values.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Create a new column on the users_df DataFrame and populate this with\n",
    "# the Series we just created\n",
    "users_df['salary'] = values\n",
    "print(users_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# We can access multiple columns of this new DataFrame as follows.\n",
    "print(\"Occupation and Salary of the first 5 users:\\n{}\".\n",
    "      format(users_df[['occupation', 'salary']].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Wait! We might not want to associate a salary to each entry!\n",
    "For example, you don't want to assign a salary to any user aged less than 18\n",
    "or anyone who doesn't have a job or is a student.\n",
    "Let's see what are the set of occupations.\n",
    "\"\"\"\n",
    "users_df['occupation'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Create a mask to assign a salary only to those users who are at least 18 AND\n",
    "are not student nor unoccupied.\n",
    "We therefore set salary to 0 for any of the users above\n",
    "\"\"\"\n",
    "mask = (users_df.age >= 18) & ~(users_df.occupation.isin(['student', 'none']))\n",
    "# mask = (users_df.age >= 18) & (users_df.occupation != 'student') \\\n",
    "# & (users_df.occupation != 'none')\n",
    "# mask = (users_df.age >= 18) & ~(users_df.occupation == 'student') \\\n",
    "# & ~(users_df.occupation == 'none')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (users_df.age >= 18) & ~(users_df.occupation.isin(['student', 'none']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(mask, users_df['salary'], 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "#users_df['salary'] = users_df['salary'].where(mask, 0)\n",
    "# Alternatively\n",
    "users_df['salary'] = np.where(mask, users_df['salary'], 0)\n",
    "users_df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Use integer slicing (special behavior to select rows)\n",
    "\"\"\"\n",
    "# Note that this integer slicing operator cannot be extended on both axis,\n",
    "# as we did for 2-D numpy arrays. In other words, you cannot use the same\n",
    "# syntax to slice over rows and columns with something like \n",
    "# users2[i_start:i_stop, j_start:j_stop]\n",
    "# In order to use integer slicing on BOTH axis as above, we need to use the .iloc method\n",
    "print(\"First 7 rows of the DataFrame:\\n{}\".format(users_df[:7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Select all the users in the DataFrame whose salary is greater than 500k\n",
    "\"\"\"\n",
    "# This is a boolean mask which returns a Series containing either True or False\n",
    "# corresponding to each entry index of the DataFrame depending on whether that entry\n",
    "# has a salary which is greater than 500k or not.\n",
    "mask = users_df.salary > 500000\n",
    "\n",
    "print(mask.head(7))\n",
    "print()\n",
    "print(\"The list of first 5 users having salary greater than 500k is:\\n{}\"\n",
    "      .format(users_df[mask].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose I want to select only female users whose salary is greater than 500k\n",
    "\"\"\"\n",
    "mask = (users_df.salary > 500000) & (users_df.gender == 'F')\n",
    "print(mask.head(7))\n",
    "print()\n",
    "print(\"The list of first 5 female users having salary greater than 500k is:\\n{}\"\n",
    "      .format(users_df[mask].head()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's use loc and iloc methods to index both axis (i.e., rows and columns)\n",
    "using either index/column labels (loc) or integers (iloc).\n",
    "\"\"\"\n",
    "# Note that in this special case, index (row) labels are integers...\n",
    "# In cases like this, loc falls back to work like .iloc\n",
    "print(\"user_id: 1 and 4 (ROWS); gender, salary, zip_code (COLUMNS):\\n{}\"\n",
    "      .format(users_df.loc[[1, 4], ['gender', 'salary', 'zip_code']]))\n",
    "\n",
    "print()\n",
    "\n",
    "print(\"user_id: 1 and 4 (ROWS); 2nd, 5th, 4th (COLUMNS):\\n{}\"\n",
    "      .format(users_df.iloc[[0, 3], [1, 4, 3]]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to sort the DataFrame by age (ascending) and salary (descending)\n",
    "\"\"\"\n",
    "print(users_df.sort_values(by=['age', 'salary'], ascending=[True, False]).tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To make the above more meaningful, let's just consider only when salary is > 0\n",
    "\"\"\"\n",
    "print(users_df[users_df.salary > 0].sort_values(by=['age', 'salary'], \n",
    "                                                ascending=[True, False]).head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Suppose we want to see what is the average salary of the users.\n",
    "\"\"\"\n",
    "# Let's first consider ALL the users (also those who have 0 salary)\n",
    "print(\"The average salary across ALL the users is: {:.2f}\"\n",
    "      .format(users_df.salary.mean()))\n",
    "\n",
    "# Let's now filter out from the mean computation any user whose salary is 0\n",
    "print(\"The average salary across all working users is: {:.2f}\"\n",
    "      .format(users_df[users_df.salary > 0].salary.mean()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's see what is the median age of the users in our DataFrame.\n",
    "\"\"\"\n",
    "print(\"The median age across ALL the users is: {}\"\n",
    "      .format(users_df.age.median()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Let's see what happens if we call 'describe()' on this DataFrame\n",
    "\"\"\"\n",
    "print(users_df.describe()) # Notice, only numeric columns are part of the description!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "# Let's try to include all the columns in the description\n",
    "print(users_df.describe(include = \"all\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Sometimes it is useful to know how the values of a particular attribute (i.e., column)\n",
    "is distributed over the data instances that we have.\n",
    "\"\"\"\n",
    "# Let's first see how many unique occupations are on our dataset (already saw this above)\n",
    "unique_occupations = users_df.occupation.unique()\n",
    "\n",
    "print(\"There are {} unique occupation values, which are as follows:\\n[{}]\"\n",
    "      .format(unique_occupations.shape[0], \n",
    "              \", \".join([o.title() for o in np.sort(unique_occupations)])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now let's see how many times each unique value of the 'occupation' column\n",
    "appears across the dataset. In other words, we compute the frequency count (a.k.a. histogram)\n",
    "of the 'occupation' attribute.\n",
    "\"\"\"\n",
    "print(\"Histogram of occupation values:\\n{}\"\n",
    "      .format(pd.value_counts(users_df.occupation, sort=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Working with other text formats\n",
    "\n",
    "-  Plain text files, such as <code>**.csv**</code> or <code>**.tsv**</code>, are not the only formats we might need work with.\n",
    "\n",
    "-  Other possible \"text\" formats can be: **JSON** (**J**ava**S**cript **O**bject **N**otation), **XML**/**HTML**, etc.\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
